# Deep Learning for NLP - PyTorch Implementation

This repository contains PyTorch implementations of laboratory assignments from the **Natural Language Processing for Deep Learning** course at UPV/EHU (University of the Basque Country), provided by [HiTZ Zentroa](https://www.hitz.eus/).

## About

These labs were originally developed using Keras/TensorFlow. This repository presents a complete rework of all assignments using **PyTorch**, maintaining the same concepts and learning objectives while leveraging PyTorch's API and design patterns.

## Labs

The course consists of 5 hands-on laboratories covering fundamental deep learning architectures for NLP:

1. **Logistic Regression** - Introduction to neural networks with a simple classification model
2. **Multi-Layer Perceptron (MLP)** - Building deeper feed-forward networks
3. **LSTMs** - Sequential modeling with Long Short-Term Memory networks
4. **Attention for NLI** - Attention mechanisms for Natural Language Inference tasks
5. **Transformers** - Modern transformer architectures for NLP

## Repository Structure

Each lab is available in two versions:
- **Keras version** (`*_with_Keras_sol.ipynb`) - Original implementations
- **PyTorch version** (`*_with_Pytorch.ipynb`) - Reworked implementations

## Requirements

For running the PyTorch implementations:
```bash
pip install torch numpy jupyter matplotlib
```

## Acknowledgments

Course materials provided by HiTZ Zentroa, UPV/EHU.
